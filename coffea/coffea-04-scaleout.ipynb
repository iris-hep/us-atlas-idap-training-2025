{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2496b17",
   "metadata": {},
   "source": [
    "# Scaleout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96e454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import awkward as ak\n",
    "import dask\n",
    "from hist.dask import Hist\n",
    "from coffea import dataset_tools\n",
    "from coffea.nanoevents import PHYSLITESchema\n",
    "from coffea.analysis_tools import PackedSelection\n",
    "\n",
    "PHYSLITESchema.warn_missing_crossrefs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9130f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib.metadata import version\n",
    "\n",
    "for package in [\"numpy\", \"awkward\", \"uproot\", \"coffea\", \"dask\"]:\n",
    "    print(f\"# {package}: v{version(package)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0563e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_name(name):\n",
    "    \"\"\"\n",
    "    Load only the properties/variables needed.\n",
    "    \"\"\"\n",
    "    return name in (\n",
    "        \"EventInfoAuxDyn.mcEventWeights\",\n",
    "        #\n",
    "        \"AnalysisElectronsAuxDyn.pt\",\n",
    "        \"AnalysisElectronsAuxDyn.eta\",\n",
    "        \"AnalysisElectronsAuxDyn.phi\",\n",
    "        \"AnalysisElectronsAuxDyn.m\",\n",
    "        \"AnalysisElectronsAuxDyn.DFCommonElectronsLHLoose\",\n",
    "        \"AnalysisElectronsAuxDyn.charge\",\n",
    "        #\n",
    "        \"AnalysisMuonsAuxDyn.pt\",\n",
    "        \"AnalysisMuonsAuxDyn.eta\",\n",
    "        \"AnalysisMuonsAuxDyn.phi\",\n",
    "        \"AnalysisMuonsAuxDyn.m\",\n",
    "        \"AnalysisMuonsAuxDyn.charge\",\n",
    "        \"AnalysisMuonsAuxDyn.quality\",\n",
    "        #\n",
    "        \"AnalysisJetsAuxDyn.pt\",\n",
    "        \"AnalysisJetsAuxDyn.eta\",\n",
    "        \"AnalysisJetsAuxDyn.phi\",\n",
    "        \"AnalysisJetsAuxDyn.m\",\n",
    "        #\n",
    "        \"BTagging_AntiKt4EMPFlowAuxDyn.DL1dv01_pb\",\n",
    "        \"BTagging_AntiKt4EMPFlowAuxDyn.DL1dv01_pc\",\n",
    "        \"BTagging_AntiKt4EMPFlowAuxDyn.DL1dv01_pu\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "971c8216",
   "metadata": {},
   "outputs": [],
   "source": [
    "GeV = 1000\n",
    "\n",
    "\n",
    "def object_selection(events):\n",
    "    \"\"\"\n",
    "    Select objects based on kinematic and quality criteria\n",
    "    \"\"\"\n",
    "\n",
    "    electrons = events.Electrons\n",
    "    muons = events.Muons\n",
    "\n",
    "    electron_reqs = (\n",
    "        (electrons.pt / GeV > 20)\n",
    "        & (np.abs(electrons.eta) < 2.47)\n",
    "        & (electrons.DFCommonElectronsLHLoose == 1)\n",
    "    )\n",
    "\n",
    "    muon_reqs = (muons.pt / GeV > 20) & (np.abs(muons.eta) < 2.7) & (muons.quality == 2)\n",
    "\n",
    "    # only keep objects that pass our requirements\n",
    "    electrons = electrons[electron_reqs]\n",
    "    muons = muons[muon_reqs]\n",
    "\n",
    "    return electrons, muons\n",
    "\n",
    "\n",
    "def region_selection(electrons, muons):\n",
    "    \"\"\"\n",
    "    Select events based on object multiplicity\n",
    "    \"\"\"\n",
    "\n",
    "    selections = PackedSelection(dtype=\"uint64\")\n",
    "    # basic selection criteria\n",
    "    selections.add(\"exactly_4e\", ak.num(electrons) == 4)\n",
    "    selections.add(\"total_e_charge_zero\", ak.sum(electrons.charge, axis=1) == 0)\n",
    "    selections.add(\"exactly_0m\", ak.num(muons) == 0)\n",
    "    # selection criteria combination\n",
    "    selections.add(\n",
    "        \"4e0m\", selections.all(\"exactly_4e\", \"total_e_charge_zero\", \"exactly_0m\")\n",
    "    )\n",
    "\n",
    "    return selections.all(\"4e0m\")\n",
    "\n",
    "\n",
    "def calculate_inv_mass(electrons):\n",
    "    \"\"\"\n",
    "    Construct invariant mass observable\n",
    "    \"\"\"\n",
    "\n",
    "    # reconstruct Higgs as 4e system\n",
    "    candidates = ak.combinations(electrons, 4)\n",
    "    e1, e2, e3, e4 = ak.unzip(candidates)\n",
    "    candidates[\"p4\"] = e1 + e2 + e3 + e4\n",
    "    higgs_mass = candidates[\"p4\"].mass\n",
    "    observable = ak.flatten(higgs_mass / GeV)\n",
    "\n",
    "    return observable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "370ac443",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create histogram with observables\n",
    "def create_histogram(events):\n",
    "    hist_4e0m = (\n",
    "        Hist.new.Reg(50, 100, 150, name=\"m_inv\", label=r\"$m_{inv.}(4e)$ [GeV]\")\n",
    "        .StrCat([], name=\"process\", label=\"Process\", growth=True)\n",
    "        .Weight()\n",
    "    )\n",
    "\n",
    "    # read metadata\n",
    "    process_name = events.metadata[\"process\"]\n",
    "    x_sec = events.metadata[\"xsec\"]\n",
    "    gen_filt_eff = events.metadata[\"genFiltEff\"]\n",
    "    k_factor = events.metadata[\"kFactor\"]\n",
    "    sum_of_weights = events.metadata[\"sumOfWeights\"]\n",
    "\n",
    "    # as mentined already, the actual analysis code remains the same!\n",
    "    # select objects and events\n",
    "    el, mu = object_selection(events)\n",
    "    selection_4e0m = region_selection(el, mu)\n",
    "\n",
    "    # normalization for MC\n",
    "    lumi = 36100.0  # /pb This is the luminosity (the amount of real data collected) corresponding to the open data released\n",
    "    xsec_weight = x_sec * gen_filt_eff * k_factor * lumi / sum_of_weights\n",
    "    print(f\"Processing {process_name} with xsec weight {xsec_weight}\")\n",
    "    mc_weight = events.EventInfo[selection_4e0m][:, 1][\"mcEventWeights\"]\n",
    "\n",
    "    # observable calculation and histogram filling\n",
    "    inv_mass = calculate_inv_mass(el[selection_4e0m])\n",
    "    hist_4e0m.fill(inv_mass, weight=mc_weight * xsec_weight, process=process_name)\n",
    "\n",
    "    return hist_4e0m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "340eb48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xcache_caching_server = \"root://xcache.af.uchicago.edu:1094//\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cb24ad",
   "metadata": {},
   "source": [
    "The metadata for open data is available by the [metadata table](https://opendata.atlas.cern/docs/documentation/overview_data/data_research_2024#metadata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfff4dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fileset = {\n",
    "    \"Higgs\": {\n",
    "        \"files\": {\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000001.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000002.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000005.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000006.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000007.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000008.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000009.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000010.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000011.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000012.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000013.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000014.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000016.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000017.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000018.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000019.pool.root.1\": \"CollectionTree\",\n",
    "            f\"{xcache_caching_server}root://eospublic.cern.ch//eos/opendata/atlas/rucio/mc20_13TeV/DAOD_PHYSLITE.38191712._000020.pool.root.1\": \"CollectionTree\",\n",
    "        },\n",
    "        \"metadata\": {\n",
    "            \"process\": \"Higgs\",\n",
    "            \"xsec\": 28.3,\n",
    "            \"genFiltEff\": 1.240e-04,\n",
    "            \"kFactor\": 1.45,\n",
    "            \"sumOfWeights\": 114108.08,\n",
    "        },\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# pre-process\n",
    "samples, _ = dataset_tools.preprocess(fileset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f2a2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the task graph\n",
    "tasks = dataset_tools.apply_to_fileset(\n",
    "    create_histogram,\n",
    "    samples,\n",
    "    schemaclass=PHYSLITESchema,\n",
    "    uproot_options=dict(filter_name=filter_name),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f26673e8",
   "metadata": {},
   "source": [
    "This will take about 1 mintue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd546a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# execute\n",
    "(out,) = dask.compute(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f7e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all the histograms together, as we processed each file separately\n",
    "full_histogram = sum(hist for hist in out.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3472457",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = Path().cwd() / \"plots\"\n",
    "plot_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6780f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "artists = full_histogram.plot(histtype=\"fill\")\n",
    "\n",
    "ax = artists[0].stairs.axes\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"A.U.\")\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(plot_dir / \"higgs_mass.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d30937c",
   "metadata": {},
   "source": [
    "## Scaleout with Dask\n",
    "\n",
    "1. Select the Dask cluster in the Dask dashboard on the left\n",
    "2. Ensure that adaptive scaling is set (click the \"Scale\" button)\n",
    "3. Click and drag the box to the Jupyter notebook which will create a cell like\n",
    "\n",
    "```python\n",
    "from dask.distributed import Client\n",
    "\n",
    "client = Client(<scheduler address>)\n",
    "client\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cd7831",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Drag here\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba5436b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# execute\n",
    "(out,) = dask.compute(tasks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0639b841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stack all the histograms together, as we processed each file separately\n",
    "full_histogram = sum(hist for hist in out.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cbcd19",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dir = Path().cwd() / \"plots\"\n",
    "plot_dir.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b80176",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot\n",
    "artists = full_histogram.plot(histtype=\"fill\")\n",
    "\n",
    "ax = artists[0].stairs.axes\n",
    "ax.legend()\n",
    "ax.set_ylabel(\"A.U.\")\n",
    "\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(plot_dir / \"higgs_mass.png\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
